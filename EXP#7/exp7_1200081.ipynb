{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 Tensors\n",
        "Tensors are a specialized data structure that are very similar to arrays and matrices.\n",
        "In PyTorch, we use tensors to encode the inputs and outputs of a model, as well\n",
        "as the model’s parameters. Tensors are similar to NumPy’s ndarrays, except that\n",
        "tensors can run on GPUs or other specialized hardware to accelerate computing.\n",
        "Let’s start by importing pytorch and numpy"
      ],
      "metadata": {
        "id": "uoPBoxOv0_9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Initialization"
      ],
      "metadata": {
        "id": "PjPFvsGH1FdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing pytorch and numpy\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-DyOVuVK1L3j"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors can be initialized in various ways. Take a look at the following examples:\n",
        "1. Directly from data\n",
        "Tensors can be created directly from data. The data type is automatically\n",
        "inferred."
      ],
      "metadata": {
        "id": "CULYgnsV1Swo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "Z5-GH4jL1HnW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. From a NumPy array\n",
        "Tensors can be created from NumPy arrays"
      ],
      "metadata": {
        "id": "AETDsSVd1jAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "GpQWOz_x1kgy"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. From another tensor:\n",
        "The new tensor retains the properties (shape, datatype) of the argument tensor,\n",
        "unless explicitly overridden."
      ],
      "metadata": {
        "id": "oT5vVztu1oi9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "PfiSAxRSUOX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5d108c-dbf4-486e-8ed5-aa8eecfc0df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.3959, 0.8753],\n",
            "        [0.9338, 0.4203]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. With random or constant values:\n",
        "shape is a tuple of tensor dimensions. In the functions below, it determines the\n",
        "dimensionality of the output tensor."
      ],
      "metadata": {
        "id": "1p5Ky-y712sH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2, 3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxKUPsHQ14xT",
        "outputId": "e2eec209-d39e-42e0-9030-792f0c905cd2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.5403, 0.3580, 0.3986],\n",
            "        [0.2925, 0.1104, 0.8765]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Attributes"
      ],
      "metadata": {
        "id": "gOZtWLWt1_JQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor attributes describe their shape, datatype, and the device on which they are\n",
        "stored."
      ],
      "metadata": {
        "id": "DWMMEAeB2AZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFrAow7T2E_c",
        "outputId": "ea4d96f5-3fe9-4ec6-d63a-c86033518a62"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Operations"
      ],
      "metadata": {
        "id": "zFPLfxgW2IPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Over 100 tensor operations, including transposing, indexing, slicing, mathematical\n",
        "operations, linear algebra, random sampling, and more are described here.\n",
        "Each of them can be run on the GPU (at typically higher speeds than on a CPU). If\n",
        "you’re using Colab, allocate a GPU by going to Edit > Notebook Settings."
      ],
      "metadata": {
        "id": "yl2f4C3j2Qwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7fMmicy2TxT",
        "outputId": "9cb7c897-3051-4625-c1e6-028fb0ed9318"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try out some of the operations from the list. If you’re familiar with the NumPy\n",
        "API, you’ll find the Tensor API a breeze to use.\n",
        "1. Standard numpy-like indexing and slicing:"
      ],
      "metadata": {
        "id": "NNPwI92f239Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "vSUKRT2c26DR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2fd1c9e-efd1-44bb-d815-24f9586f5c13"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Joining tensors\n",
        "You can use torch.cat to concatenate a sequence of tensors along a given\n",
        "dimension. See also torch.stack, another tensor joining op that is subtly\n",
        "different from torch.cat."
      ],
      "metadata": {
        "id": "yrpQQx9C281n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "id": "4MSRwNji2_r-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba526ecd-7273-41d8-a653-dabe2b1d76b8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Multiplying tensors"
      ],
      "metadata": {
        "id": "PVqciFSy3DQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the element-wise product\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "metadata": {
        "id": "DtG6VR2a3GLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57ab10a-283f-4c4d-93a9-5bb157d5f1cc"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.mul(tensor) \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This computes the matrix multiplication between two tensors.\n",
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "metadata": {
        "id": "E3gmp-4o3HU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185756ff-298e-445a-97c1-5801ce052fdc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. In-place operations\n",
        "Operations that have a suffix are in-place. For example: x.copy (y), x.t (),\n",
        "will change x."
      ],
      "metadata": {
        "id": "3zhYrdi23Ptc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "D0y0OiX93RTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072e76f7-2005-4562-8a4e-ee5d93ad907a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bridge with NumPy"
      ],
      "metadata": {
        "id": "C7IzKZBc3VEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors on the CPU and NumPy arrays can share their underlying memory locations,\n",
        "and changing one will change the other.\n",
        "Tensor to NumPy array: A change in the tensor reflects in the NumPy array."
      ],
      "metadata": {
        "id": "qlpuKKZF3Yoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")\n",
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "id": "-a9nsouD3aaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee917587-6065-427f-bb4f-1a14f4c354aa"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n",
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy array to Tensor: Changes in the NumPy array reflects in the tensor."
      ],
      "metadata": {
        "id": "WfQRLwYS3cul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)\n",
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "id": "yemoOP3Q3dVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670957a5-cf5e-4846-def2-055eafb5de60"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2 A Gentle Introduction to torch.autograd"
      ],
      "metadata": {
        "id": "BkR-ZNzL3iLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.autograd is PyTorch’s automatic differentiation engine that powers neural\n",
        "network training. In this section, you will get a conceptual understanding of how\n",
        "autograd helps a neural network train.\n",
        "Background\n",
        "Neural networks (NNs) are a collection of nested functions that are executed on some\n",
        "input data. These functions are defined by parameters (consisting of weights and\n",
        "biases), which in PyTorch are stored in tensors.\n",
        "Training a NN happens in two steps:\n",
        "Forward Propagation: In forward prop, the NN makes its best guess about the correct\n",
        "output. It runs the input data through each of its functions to make this guess.\n",
        "Backward Propagation: In backprop, the NN adjusts its parameters proportionate to\n",
        "the error in its guess. It does this by traversing backwards from the output, collecting\n",
        "\n",
        "the derivatives of the error with respect to the parameters of the functions (gradi-\n",
        "ents), and optimizing the parameters using gradient descent."
      ],
      "metadata": {
        "id": "vOWVUhEx3jqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Differentiation in Autograd\n",
        "Let’s take a look at how autograd collects gradients. We create two tensors a and b\n",
        "with requires grad=True. This signals to autograd that every operation on them\n",
        "should be tracked."
      ],
      "metadata": {
        "id": "xZBpFyJ43nTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)"
      ],
      "metadata": {
        "id": "P5lj2_Gi3sEO"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if collected gradients are correct\n",
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ],
      "metadata": {
        "id": "Nd6__WBj304v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c7f7d1-5e45-4d2e-b14f-a4415dc51bfd"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Use autograd to compute the gradients of Y w.r.t. x1 and x2 at the point\n",
        "(x1, x2) = (1, 1). Where\n",
        "\n",
        "Y = (3x1 − 2x2 − 2)2\n",
        ".\n",
        "Verify your results by computing the gradients analytically."
      ],
      "metadata": {
        "id": "Ask1Nv943uoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.tensor(1.0, requires_grad=True)\n",
        "x2 = torch.tensor(1.0, requires_grad=True)\n",
        "Y = (3*x1 - 2*x2 - 2)**2\n",
        "Y.backward()\n",
        "print(x1.grad)\n",
        "print(x2.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHvv9Xl0flRi",
        "outputId": "676114d4-7ed5-467b-e002-7cf16b681919"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-6.)\n",
            "tensor(4.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.3 Building Models with PyTorch"
      ],
      "metadata": {
        "id": "wm6tUaC7360F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural networks can be constructed using the torch.nn package. Now that you had\n",
        "a glimpse of autograd, nn depends on autograd to define models and differentiate\n",
        "them. An nn.Module contains layers, and a method forward(input) that returns\n",
        "the output.\n",
        "A typical training procedure for a neural network is as follows:\n",
        "• Define the neural network that has some learnable parameters (or weights)\n",
        "• Iterate over a dataset of inputs\n",
        "• Process input through the network\n",
        "• Compute the loss (how far is the output from being correct)\n",
        "• Propagate gradients back into the network’s parameters\n",
        "• Update the weights of the network, typically using a simple update rule:\n",
        "weight = weight - learning rate * gradient\n",
        "For example, look at this network that classifies digit images. It is a simple feed-\n",
        "forward network. It takes the input, feeds it through two hidden layers one after the\n",
        "\n",
        "other, and then finally gives the output, which is 10 neurons each corresponds to a\n",
        "different class (digit 0, 1, ..., 9).\n",
        "Now, let’s build and train the MLP"
      ],
      "metadata": {
        "id": "ark5T6s-3-EX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the network\n",
        "Let’s define this network:"
      ],
      "metadata": {
        "id": "iVWwNHOI4FGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # an affine operation: y = Wx + b\n",
        "    # 784 is the input dimension, and 68 is the output dimenstion o the first hidden layer\n",
        "    self.fc1 = nn.Linear(784, 64)\n",
        "    self.fc2 = nn.Linear(64, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "  def forward(self, x):\n",
        "    # apply the first layer with relu activation\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "metadata": {
        "id": "a-yKjKTE4Hmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a7f4f25-55cc-46bd-94f1-a58cb1108dbe"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You just have to define the forward function, and the backward function (where\n",
        "gradients are computed) is automatically defined for you using autograd. You can\n",
        "use any of the Tensor operations in the forward function.\n",
        "The learnable parameters of a model are returned by net.parameters()"
      ],
      "metadata": {
        "id": "DpI4L3X94U2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "for p in params:\n",
        "  print(p.size())"
      ],
      "metadata": {
        "id": "RXxezm6X4V96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b25a10e-9765-4366-aa88-2c7963dd8e32"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "torch.Size([64, 784])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 64])\n",
            "torch.Size([64])\n",
            "torch.Size([10, 64])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Identify what are the parameters that are printed in the previous code.\n",
        "Let’s try a random input. Note: expected input size of this network is 784."
      ],
      "metadata": {
        "id": "goQ38RfZ4Xxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(1, 784)\n",
        "out = net(input)\n",
        "print(out)\n",
        "out.shape"
      ],
      "metadata": {
        "id": "5MZSqw1y4bwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc90dc9-f76f-497d-909a-6566c43ed177"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0489, -0.0013, -0.0138, -0.2011, -0.0620, -0.1763,  0.1597, -0.2246,\n",
            "         -0.1772,  0.1315]], grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that torch.nn only supports mini-batches. The entire torch.nn package only\n",
        "supports inputs that are a mini-batch of samples, and not a single sample. That’s\n",
        "the reason why we add an additional dimension for the input tensor.\n",
        "\n",
        "Task 3: Try the previous network with a random mini-batch of size 4 and print its\n",
        "output."
      ],
      "metadata": {
        "id": "FsLjInkM4eL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(4, 784)\n",
        "out = net(input)\n",
        "print(out)\n",
        "out.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0otitQQnzwY",
        "outputId": "df108711-a8dc-43b4-d622-1f3feee9a547"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0896, -0.0044,  0.0450, -0.1868, -0.0203, -0.1380,  0.0661, -0.1740,\n",
            "         -0.1125, -0.0052],\n",
            "        [ 0.0015, -0.0726, -0.0094, -0.1361, -0.0510, -0.1156,  0.0165, -0.2094,\n",
            "         -0.1062,  0.0341],\n",
            "        [-0.0557,  0.0118, -0.0300, -0.2104, -0.0329, -0.0495, -0.0568, -0.1601,\n",
            "         -0.0897,  0.0063],\n",
            "        [ 0.0021, -0.1117, -0.0715, -0.1929, -0.1021, -0.0675, -0.0533, -0.1202,\n",
            "         -0.1881, -0.0716]], grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a Loss function and optimizer"
      ],
      "metadata": {
        "id": "obHa7xcC4mQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "_-NQFmuK4oym"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the input to nn.CrossEntropyLoss() is expected to contain the unnor-\n",
        "malized logits for each class. That’s why we do not use softmax activation for the\n",
        "\n",
        "last layer of the network.\n",
        "What about data?\n",
        "To train the network, you need to iterate over your dataset and feed it to the network\n",
        "as mini-batches in the training loop. PyTorch provides two classes to make this\n",
        "process easier: Dataset and Dataloader. The Dataset and DataLoader classes\n",
        "encapsulate the process of pulling your data from storage and exposing it to your\n",
        "training loop in batches.\n",
        "The Dataset is responsible for accessing and processing single instances of data. The\n",
        "DataLoader pulls instances of data from the Dataset (either automatically or with a\n",
        "sampler that you define), collects them in batches, and returns them for consumption\n",
        "by your training loop. The DataLoader works with all kinds of datasets, regardless\n",
        "of the type of data they contain.\n",
        "PyTorch domain libraries provide a number of pre-loaded datasets (such as MNIST)\n",
        "that subclass torch.utils.data.Dataset and implement functions specific to the\n",
        "particular data. They can be used to prototype and benchmark your model. In this\n",
        "experiment, we will use the MNIST dataset, which contains images of handwritten\n",
        "digits. It has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
        "Each example comprises a 28×28 grayscale image and an associated label from one\n",
        "of 10 classes (digit 0, 1, ..., 9)."
      ],
      "metadata": {
        "id": "o_wv1Bys4rbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a Dataset\n",
        "Here is an example of how to load the MNIST dataset from TorchVision.\n",
        "We load the MNIST Dataset with the following parameters:\n",
        "\n",
        "• root is the path where the train/test data is stored.\n",
        "\n",
        "• train specifies training or test dataset.\n",
        "• download=True downloads the data from the internet if it’s not available at\n",
        "root.\n",
        "\n",
        "• transform and target transform specify the feature and label transforma-\n",
        "tions."
      ],
      "metadata": {
        "id": "t_dWUOrc4xOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "training_data = datasets.MNIST(\n",
        "root=\"data\",\n",
        "train=True,\n",
        "download=True,\n",
        "transform=ToTensor()\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "root=\"data\",\n",
        "train=False,\n",
        "download=True,\n",
        "transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "d0ex2lUx43oi"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterating and Visualizing the Dataset\n",
        "We can index Datasets manually like a list: training data[index]. We use matplotlib\n",
        "to visualize some samples in our training data."
      ],
      "metadata": {
        "id": "bETPrqJj445I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "  sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "  img, label = training_data[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(\"digit:\" + str(label))\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C0I1CXfK4sr3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "2bdf3256-fa8c-4660-b806-ed8d4a436062"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing your data for training with DataLoaders\n",
        "\n",
        "The Dataset retrieves our dataset’s features and labels one sample at a time. While\n",
        "training a model, we typically want to pass samples in “minibatches”, reshuffle the\n",
        "data at every epoch to reduce model overfitting, and use Python’s multiprocessing\n",
        "to speed up data retrieval.\n",
        "DataLoader is an iterable that abstracts this complexity for us in an easy API."
      ],
      "metadata": {
        "id": "TPKHeHHT5Bl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(training_data, batch_size=4, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "wcSJVOHd5CpO"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iterate through the DataLoader\n",
        "We have loaded that dataset into the DataLoader and can iterate through the dataset\n",
        "as needed. Each iteration below returns a batch of train features and train labels\n",
        "(containing batch size=4 features and labels respectively). Because we specified\n",
        "shuffle=True, after we iterate over all batches the data is shuffled."
      ],
      "metadata": {
        "id": "1wG3RN7C5Ghm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "laPKQFXc5KvF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "e2a47f61-e8ec-4c48-8678-ce0b30d39dc1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([4, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([4])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the network\n",
        "This is when things start to get interesting. We simply have to loop over our data\n",
        "iterator, and feed the inputs to the network and optimize."
      ],
      "metadata": {
        "id": "MpJR0Mtq5P6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2): # loop over the dataset multiple times\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "  # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "  # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(torch.flatten(inputs,1))\n",
        "    iteration_loss = loss(outputs, labels)\n",
        "    iteration_loss.backward()\n",
        "    optimizer.step()\n",
        "    # print statistics\n",
        "    running_loss += iteration_loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss /2000:.3f}')\n",
        "      running_loss = 0.0\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "HFKpt_hn5OLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0160dd58-bea1-4b37-90be-85cc6fac76fb"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.281\n",
            "[1,  4000] loss: 2.173\n",
            "[1,  6000] loss: 1.872\n",
            "[1,  8000] loss: 1.361\n",
            "[1, 10000] loss: 0.927\n",
            "[1, 12000] loss: 0.699\n",
            "[1, 14000] loss: 0.577\n",
            "[2,  2000] loss: 0.496\n",
            "[2,  4000] loss: 0.454\n",
            "[2,  6000] loss: 0.444\n",
            "[2,  8000] loss: 0.418\n",
            "[2, 10000] loss: 0.417\n",
            "[2, 12000] loss: 0.395\n",
            "[2, 14000] loss: 0.387\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4: What is the meaning of epoch, forward pass, backward pass. What is\n",
        "the effect of torch.flatten(inputs, 1), and optimizer.step()?\n",
        "\n"
      ],
      "metadata": {
        "id": "SnXvDV3G5kGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch: The number of complete cycles in which all training data is passed through the neural network at once.\n",
        "\n",
        "Forward Pass: The process of feeding data through the neural network to calculate the output.\n",
        "\n",
        "Backward Pass: The process of calculating gradients using backpropagation to update the weights.\n",
        "\n",
        "torch.flatten(inputs, 1): Flattens the inputs into a 1D shape for each sample, to match the first layer.\n",
        "\n",
        "optimizer.step(): Uses the gradients determined in the preceding step to update the model weights."
      ],
      "metadata": {
        "id": "vpmOe156S6dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To save our trained model, we can use the following code:"
      ],
      "metadata": {
        "id": "S_u0J76uzEsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './my_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "H8M4Sq105ksO"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the network on the test data\n",
        "We have trained the network for 2 passes over the training dataset. But we need to\n",
        "check if the network has learnt anything at all.\n",
        "We will check this by predicting the class label that the neural network outputs, and\n",
        "checking it against the ground-truth. If the prediction is correct, we add the sample\n",
        "to the list of correct predictions. The outputs are energies for the 10 classes. The\n",
        "higher the energy for a class, the more the network thinks that the image is of the\n",
        "particular class. So, we get the prediction by finding the index of the highest energy.\n",
        "Let’s load back in our saved model (note: saving and re-loading the model wasn’t\n",
        "necessary here, we only did it to illustrate how to do so):"
      ],
      "metadata": {
        "id": "6_cBqfRn5mcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "vC3mv4hT5o0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb02789-fc78-401b-c917-b19e19575b5c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-8b61435874a9>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(PATH))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s look at how the network performs on the whole testing dataset."
      ],
      "metadata": {
        "id": "YV56yO0I5uEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "  for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    # calculate outputs by running images through the network\n",
        "    outputs = net(torch.flatten(images,1))\n",
        "    # the class with the highest energy is what we choose as prediction\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct// total} %')"
      ],
      "metadata": {
        "id": "v8Tf5Mw25v1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a19e3b-5fca-4d4a-d61b-e1a1a5217321"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 89 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5: Train the network in the previous example, but instead of using 2 hidden\n",
        "layers, try 3 hidden layers."
      ],
      "metadata": {
        "id": "Sdfh1mOK58LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # an affine operation: y = Wx + b\n",
        "    # 784 is the input dimension, and 68 is the output dimenstion o the first hidden layer\n",
        "    self.fc1 = nn.Linear(784, 64)\n",
        "    self.fc2 = nn.Linear(64, 64)\n",
        "    self.fc3 = nn.Linear(64, 64)\n",
        "    self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # apply the first layer with relu activation\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "  for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    # calculate outputs by running images through the network\n",
        "    outputs = net(torch.flatten(images,1))\n",
        "    # the class with the highest energy is what we choose as prediction\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct// total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2lH_G91rnD_",
        "outputId": "c7781af7-e540-4aa7-dfa3-60e244a7c5c6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Accuracy of the network on the 10000 test images: 12 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 6: Train the network in the previous example using Adam optimizer."
      ],
      "metadata": {
        "id": "-jU88EL_5-WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "import torch.optim as optim\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "for epoch in range(2): # loop over the dataset multiple times\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "  # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "  # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(torch.flatten(inputs,1))\n",
        "    iteration_loss = loss(outputs, labels)\n",
        "    iteration_loss.backward()\n",
        "    optimizer.step()\n",
        "    # print statistics\n",
        "    running_loss += iteration_loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss /2000:.3f}')\n",
        "      running_loss = 0.0\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "  for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    # calculate outputs by running images through the network\n",
        "    outputs = net(torch.flatten(images,1))\n",
        "    # the class with the highest energy is what we choose as prediction\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct// total} %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc_Ke9M350E4",
        "outputId": "c688a3fb-36b2-4fc2-fd16-4bfc9c48d586"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 0.514\n",
            "[1,  4000] loss: 0.267\n",
            "[1,  6000] loss: 0.212\n",
            "[1,  8000] loss: 0.190\n",
            "[1, 10000] loss: 0.157\n",
            "[1, 12000] loss: 0.159\n",
            "[1, 14000] loss: 0.155\n",
            "[2,  2000] loss: 0.119\n",
            "[2,  4000] loss: 0.115\n",
            "[2,  6000] loss: 0.119\n",
            "[2,  8000] loss: 0.117\n",
            "[2, 10000] loss: 0.113\n",
            "[2, 12000] loss: 0.113\n",
            "[2, 14000] loss: 0.120\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 97 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training on GPU\n",
        "The training in the previous example was done on CPU. But how do we train our\n",
        "model on GPU?\n",
        "Just like how you transfer a Tensor onto the GPU, you transfer the neural net onto\n",
        "the GPU. Let’s first define our device as the first visible cuda device if we have CUDA\n",
        "available:"
      ],
      "metadata": {
        "id": "T6-LLJrj6AQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)"
      ],
      "metadata": {
        "id": "EeQjSDN_6Com",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c7c4b4-3261-44df-a73e-6ad4aa51334d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rest of this section assumes that device is a CUDA device.\n",
        "Then these methods will recursively go over all modules and convert their parameters\n",
        "and buffers to CUDA tensors:"
      ],
      "metadata": {
        "id": "c0ewXmXS6FH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM6w1Ak1sMO2",
        "outputId": "8f85e53d-f8c3-4bc7-cc77-9c34ef78699e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H1Qqanwh6Hqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember that you will have to send the inputs and targets at every step to the\n",
        "GPU too:"
      ],
      "metadata": {
        "id": "gfw57WXT6KSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, labels = data[0].to(device), data[1].to(device)"
      ],
      "metadata": {
        "id": "qlHoAVSs6LKA"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 7: Train the network in the previous example on GPU. Do you notice significant\n",
        "speedup? if not, try to increase the size of your network."
      ],
      "metadata": {
        "id": "uTtLhpq76NZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "before increase the size of  network.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lRIxKQbpPMOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(2): # loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(torch.flatten(inputs,1))\n",
        "    iteration_loss = loss(outputs, labels)\n",
        "    iteration_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += iteration_loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "      running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEt1e6YMI03M",
        "outputId": "cb6f573e-fb40-43f4-9719-901c1665712b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 0.062\n",
            "[1,  4000] loss: 0.060\n",
            "[1,  6000] loss: 0.060\n",
            "[1,  8000] loss: 0.056\n",
            "[1, 10000] loss: 0.058\n",
            "[1, 12000] loss: 0.065\n",
            "[1, 14000] loss: 0.059\n",
            "[2,  2000] loss: 0.056\n",
            "[2,  4000] loss: 0.046\n",
            "[2,  6000] loss: 0.053\n",
            "[2,  8000] loss: 0.052\n",
            "[2, 10000] loss: 0.054\n",
            "[2, 12000] loss: 0.052\n",
            "[2, 14000] loss: 0.053\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after increase the size of  network."
      ],
      "metadata": {
        "id": "G4e9jyLdPQAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # an affine operation: y = Wx + b\n",
        "\n",
        "    self.fc1 = nn.Linear(784, 128)\n",
        "    self.fc2 = nn.Linear(128, 128)\n",
        "    self.fc3 = nn.Linear(128, 128)\n",
        "    self.fc4 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # apply the first layer with relu activation\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "  for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    # calculate outputs by running images through the network\n",
        "    outputs = net(torch.flatten(images,1))\n",
        "    # the class with the highest energy is what we choose as prediction\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct// total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZhzl-f_Pg8P",
        "outputId": "a261eeb6-ff79-4b67-aa92-7300f94912ce"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "Accuracy of the network on the 10000 test images: 4 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq9Ygi7_QU13",
        "outputId": "6bcdb8c5-a0b9-4ac9-a2fd-d570c242e69a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# Initialize the model and move it to the GPU (if available)\n",
        "net = Net().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# Number of epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        # Move inputs and labels to the selected device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Flatten inputs for compatibility with the network\n",
        "        inputs = torch.flatten(inputs, 1)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # Print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbeN2u7fP4kJ",
        "outputId": "a075589f-5ebf-49d6-b319-c5b8abaa38eb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 0.464\n",
            "[1,  4000] loss: 0.237\n",
            "[1,  6000] loss: 0.199\n",
            "[1,  8000] loss: 0.184\n",
            "[1, 10000] loss: 0.154\n",
            "[1, 12000] loss: 0.152\n",
            "[1, 14000] loss: 0.133\n",
            "[2,  2000] loss: 0.097\n",
            "[2,  4000] loss: 0.128\n",
            "[2,  6000] loss: 0.097\n",
            "[2,  8000] loss: 0.115\n",
            "[2, 10000] loss: 0.102\n",
            "[2, 12000] loss: 0.098\n",
            "[2, 14000] loss: 0.105\n",
            "[3,  2000] loss: 0.076\n",
            "[3,  4000] loss: 0.075\n",
            "[3,  6000] loss: 0.086\n",
            "[3,  8000] loss: 0.086\n",
            "[3, 10000] loss: 0.087\n",
            "[3, 12000] loss: 0.080\n",
            "[3, 14000] loss: 0.079\n",
            "[4,  2000] loss: 0.055\n",
            "[4,  4000] loss: 0.071\n",
            "[4,  6000] loss: 0.070\n",
            "[4,  8000] loss: 0.069\n",
            "[4, 10000] loss: 0.071\n",
            "[4, 12000] loss: 0.077\n",
            "[4, 14000] loss: 0.070\n",
            "[5,  2000] loss: 0.046\n",
            "[5,  4000] loss: 0.059\n",
            "[5,  6000] loss: 0.061\n",
            "[5,  8000] loss: 0.062\n",
            "[5, 10000] loss: 0.051\n",
            "[5, 12000] loss: 0.070\n",
            "[5, 14000] loss: 0.063\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4 EXTRA (Optional) - Visualizing models, data,\n",
        "and training with tensorboard\n",
        "PyTorch integrates with TensorBoard, a tool designed for visualizing the results of\n",
        "neural network training runs. This tutorial illustrates some of its functionality."
      ],
      "metadata": {
        "id": "fAHfeQ1R6Qf4"
      }
    }
  ]
}